{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nmL9EiT_RS9k"
   },
   "source": [
    "### Importing Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zo3apvqORS9n",
    "outputId": "5c3bca0d-bddb-4936-c973-bf4fb2e70ce9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                          body_text\n",
       "0   ham  I've been searching for the right words to tha...\n",
       "1  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "2   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "3   ham  Even my brother is not like to speak with me. ...\n",
       "4   ham                I HAVE A DATE ON SUNDAY WITH WILL!!"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataNlp = pd.read_csv('SMSSpamCollection.tsv', sep='\\t', names=['label','body_text'], header=None)\n",
    "dataNlp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K2Gy-IYGRS9x",
    "outputId": "cfd46026-7938-4ae2-b6eb-4d1e71b002ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4822\n",
       "spam     746\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataNlp['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NZUzA6mrRS90"
   },
   "source": [
    "### Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_text</th>\n",
       "      <th>noPunct</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>noStopwords</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>body_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "      <td>ive been searching for the right words to than...</td>\n",
       "      <td>[ive, been, searching, for, the, right, words,...</td>\n",
       "      <td>[ive, searching, right, words, thank, breather...</td>\n",
       "      <td>[ive, searching, right, word, thank, breather,...</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "      <td>[nah, i, dont, think, he, goes, to, usf, he, l...</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
       "      <td>[nah, dont, think, go, usf, life, around, though]</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>even my brother is not like to speak with me t...</td>\n",
       "      <td>[even, my, brother, is, not, like, to, speak, ...</td>\n",
       "      <td>[even, brother, like, speak, treat, like, aids...</td>\n",
       "      <td>[even, brother, like, speak, treat, like, aid,...</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>i have a date on sunday with will</td>\n",
       "      <td>[i, have, a, date, on, sunday, with, will]</td>\n",
       "      <td>[date, sunday]</td>\n",
       "      <td>[date, sunday]</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                          body_text  \\\n",
       "0   ham  I've been searching for the right words to tha...   \n",
       "1  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "2   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "3   ham  Even my brother is not like to speak with me. ...   \n",
       "4   ham                I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
       "\n",
       "                                             noPunct  \\\n",
       "0  ive been searching for the right words to than...   \n",
       "1  free entry in 2 a wkly comp to win fa cup fina...   \n",
       "2  nah i dont think he goes to usf he lives aroun...   \n",
       "3  even my brother is not like to speak with me t...   \n",
       "4                  i have a date on sunday with will   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [ive, been, searching, for, the, right, words,...   \n",
       "1  [free, entry, in, 2, a, wkly, comp, to, win, f...   \n",
       "2  [nah, i, dont, think, he, goes, to, usf, he, l...   \n",
       "3  [even, my, brother, is, not, like, to, speak, ...   \n",
       "4         [i, have, a, date, on, sunday, with, will]   \n",
       "\n",
       "                                         noStopwords  \\\n",
       "0  [ive, searching, right, words, thank, breather...   \n",
       "1  [free, entry, 2, wkly, comp, win, fa, cup, fin...   \n",
       "2  [nah, dont, think, goes, usf, lives, around, t...   \n",
       "3  [even, brother, like, speak, treat, like, aids...   \n",
       "4                                     [date, sunday]   \n",
       "\n",
       "                                          lemmatized  body_len  \n",
       "0  [ive, searching, right, word, thank, breather,...       160  \n",
       "1  [free, entry, 2, wkly, comp, win, fa, cup, fin...       128  \n",
       "2  [nah, dont, think, go, usf, life, around, though]        49  \n",
       "3  [even, brother, like, speak, treat, like, aid,...        62  \n",
       "4                                     [date, sunday]        28  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Q1. Preprocess the data so that stopwords are removed\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "import string\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "wnl = nltk.WordNetLemmatizer()\n",
    "\n",
    "def processData(txt):\n",
    "    dataNlp['noPunct'] = txt.apply(lambda x: \"\".join([char.lower() for char in x if char not in string.punctuation]))\n",
    "    #dataNlp['tokenized'] = dataNlp.noPunct.apply(lambda x: re.split('\\W+', x))\n",
    "    dataNlp['tokenized'] = dataNlp.noPunct.apply(lambda x: word_tokenize(x))\n",
    "    dataNlp['noStopwords'] = dataNlp.tokenized.apply(lambda x: [word for word in x if word not in stopword])\n",
    "    dataNlp['lemmatized'] = dataNlp.noStopwords.apply(lambda x: [wnl.lemmatize(word) for word in x])\n",
    "    return dataNlp.lemmatized\n",
    "    \n",
    "processData(dataNlp.body_text)\n",
    "dataNlp['body_len'] = dataNlp['body_text'].apply(lambda x: len(x) - x.count(\" \"))\n",
    "dataNlp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_text</th>\n",
       "      <th>noPunct</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>noStopwords</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>body_len</th>\n",
       "      <th>punct%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "      <td>ive been searching for the right words to than...</td>\n",
       "      <td>[ive, been, searching, for, the, right, words,...</td>\n",
       "      <td>[ive, searching, right, words, thank, breather...</td>\n",
       "      <td>[ive, searching, right, word, thank, breather,...</td>\n",
       "      <td>160</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "      <td>128</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "      <td>[nah, i, dont, think, he, goes, to, usf, he, l...</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
       "      <td>[nah, dont, think, go, usf, life, around, though]</td>\n",
       "      <td>49</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>even my brother is not like to speak with me t...</td>\n",
       "      <td>[even, my, brother, is, not, like, to, speak, ...</td>\n",
       "      <td>[even, brother, like, speak, treat, like, aids...</td>\n",
       "      <td>[even, brother, like, speak, treat, like, aid,...</td>\n",
       "      <td>62</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>i have a date on sunday with will</td>\n",
       "      <td>[i, have, a, date, on, sunday, with, will]</td>\n",
       "      <td>[date, sunday]</td>\n",
       "      <td>[date, sunday]</td>\n",
       "      <td>28</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                          body_text  \\\n",
       "0   ham  I've been searching for the right words to tha...   \n",
       "1  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "2   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "3   ham  Even my brother is not like to speak with me. ...   \n",
       "4   ham                I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
       "\n",
       "                                             noPunct  \\\n",
       "0  ive been searching for the right words to than...   \n",
       "1  free entry in 2 a wkly comp to win fa cup fina...   \n",
       "2  nah i dont think he goes to usf he lives aroun...   \n",
       "3  even my brother is not like to speak with me t...   \n",
       "4                  i have a date on sunday with will   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [ive, been, searching, for, the, right, words,...   \n",
       "1  [free, entry, in, 2, a, wkly, comp, to, win, f...   \n",
       "2  [nah, i, dont, think, he, goes, to, usf, he, l...   \n",
       "3  [even, my, brother, is, not, like, to, speak, ...   \n",
       "4         [i, have, a, date, on, sunday, with, will]   \n",
       "\n",
       "                                         noStopwords  \\\n",
       "0  [ive, searching, right, words, thank, breather...   \n",
       "1  [free, entry, 2, wkly, comp, win, fa, cup, fin...   \n",
       "2  [nah, dont, think, goes, usf, lives, around, t...   \n",
       "3  [even, brother, like, speak, treat, like, aids...   \n",
       "4                                     [date, sunday]   \n",
       "\n",
       "                                          lemmatized  body_len  punct%  \n",
       "0  [ive, searching, right, word, thank, breather,...       160     2.5  \n",
       "1  [free, entry, 2, wkly, comp, win, fa, cup, fin...       128     4.7  \n",
       "2  [nah, dont, think, go, usf, life, around, though]        49     4.1  \n",
       "3  [even, brother, like, speak, treat, like, aid,...        62     3.2  \n",
       "4                                     [date, sunday]        28     7.1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Q2. Write down a function that can count percentage of punctuation marks in the text\n",
    "\n",
    "def countPunct(text):\n",
    "    count = sum([1 for char in text if char in string.punctuation])\n",
    "    return round(count/(len(text) - text.count(\" \")),3)*100\n",
    "\n",
    "dataNlp['punct%'] = dataNlp.body_text.apply(lambda x: countPunct(x))\n",
    "dataNlp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_text</th>\n",
       "      <th>body_len</th>\n",
       "      <th>punct%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "      <td>160</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>128</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>49</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>62</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>28</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                          body_text  body_len  punct%\n",
       "0   ham  I've been searching for the right words to tha...       160     2.5\n",
       "1  spam  Free entry in 2 a wkly comp to win FA Cup fina...       128     4.7\n",
       "2   ham  Nah I don't think he goes to usf, he lives aro...        49     4.1\n",
       "3   ham  Even my brother is not like to speak with me. ...        62     3.2\n",
       "4   ham                I HAVE A DATE ON SUNDAY WITH WILL!!        28     7.1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanNlp = dataNlp[['label','body_text','body_len','punct%']]\n",
    "cleanNlp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xW22NaJ3RS93"
   },
   "source": [
    "### Split into train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BqdW1B-HRS96",
    "outputId": "f6aae094-4554-4ef5-fce7-16792ddcc5e7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089mi</th>\n",
       "      <th>0121</th>\n",
       "      <th>01223585236</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>0125698789</th>\n",
       "      <th>02</th>\n",
       "      <th>020603</th>\n",
       "      <th>...</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtoriu</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>é</th>\n",
       "      <th>ü</th>\n",
       "      <th>üll</th>\n",
       "      <th>〨ud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5563</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5564</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.335215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5565</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5568 rows × 8107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  008704050406  0089mi  0121  01223585236  01223585334  \\\n",
       "0     0.0  0.0           0.0     0.0   0.0          0.0          0.0   \n",
       "1     0.0  0.0           0.0     0.0   0.0          0.0          0.0   \n",
       "2     0.0  0.0           0.0     0.0   0.0          0.0          0.0   \n",
       "3     0.0  0.0           0.0     0.0   0.0          0.0          0.0   \n",
       "4     0.0  0.0           0.0     0.0   0.0          0.0          0.0   \n",
       "...   ...  ...           ...     ...   ...          ...          ...   \n",
       "5563  0.0  0.0           0.0     0.0   0.0          0.0          0.0   \n",
       "5564  0.0  0.0           0.0     0.0   0.0          0.0          0.0   \n",
       "5565  0.0  0.0           0.0     0.0   0.0          0.0          0.0   \n",
       "5566  0.0  0.0           0.0     0.0   0.0          0.0          0.0   \n",
       "5567  0.0  0.0           0.0     0.0   0.0          0.0          0.0   \n",
       "\n",
       "      0125698789   02  020603  ...  zindgi  zoe  zogtoriu  zoom  zouk  zyada  \\\n",
       "0            0.0  0.0     0.0  ...     0.0  0.0       0.0   0.0   0.0    0.0   \n",
       "1            0.0  0.0     0.0  ...     0.0  0.0       0.0   0.0   0.0    0.0   \n",
       "2            0.0  0.0     0.0  ...     0.0  0.0       0.0   0.0   0.0    0.0   \n",
       "3            0.0  0.0     0.0  ...     0.0  0.0       0.0   0.0   0.0    0.0   \n",
       "4            0.0  0.0     0.0  ...     0.0  0.0       0.0   0.0   0.0    0.0   \n",
       "...          ...  ...     ...  ...     ...  ...       ...   ...   ...    ...   \n",
       "5563         0.0  0.0     0.0  ...     0.0  0.0       0.0   0.0   0.0    0.0   \n",
       "5564         0.0  0.0     0.0  ...     0.0  0.0       0.0   0.0   0.0    0.0   \n",
       "5565         0.0  0.0     0.0  ...     0.0  0.0       0.0   0.0   0.0    0.0   \n",
       "5566         0.0  0.0     0.0  ...     0.0  0.0       0.0   0.0   0.0    0.0   \n",
       "5567         0.0  0.0     0.0  ...     0.0  0.0       0.0   0.0   0.0    0.0   \n",
       "\n",
       "        é         ü  üll  〨ud  \n",
       "0     0.0  0.000000  0.0  0.0  \n",
       "1     0.0  0.000000  0.0  0.0  \n",
       "2     0.0  0.000000  0.0  0.0  \n",
       "3     0.0  0.000000  0.0  0.0  \n",
       "4     0.0  0.000000  0.0  0.0  \n",
       "...   ...       ...  ...  ...  \n",
       "5563  0.0  0.000000  0.0  0.0  \n",
       "5564  0.0  0.335215  0.0  0.0  \n",
       "5565  0.0  0.000000  0.0  0.0  \n",
       "5566  0.0  0.000000  0.0  0.0  \n",
       "5567  0.0  0.000000  0.0  0.0  \n",
       "\n",
       "[5568 rows x 8107 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q3. For the test and train datasets create a TfIdfVectorizer\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    #noStop = [word for word in tokens if word not in stopword]\n",
    "    #lem = [wnl.lemmatize(word) for word in noStop]\n",
    "    lem = [ps.stem(word) for word in tokens if word not in stopword]\n",
    "    return lem\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfVect = TfidfVectorizer(analyzer=clean_text)\n",
    "xtfTrain = tfVect.fit_transform(cleanNlp.body_text)\n",
    "#xtfTest = tfVect.fit_transform(X_test)\n",
    "X = pd.DataFrame(xtfTrain.toarray(), columns = tfVect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_len</th>\n",
       "      <th>punct%</th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089mi</th>\n",
       "      <th>0121</th>\n",
       "      <th>01223585236</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>...</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtoriu</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>é</th>\n",
       "      <th>ü</th>\n",
       "      <th>üll</th>\n",
       "      <th>〨ud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>160</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>128</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>49</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>62</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>28</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5563</th>\n",
       "      <td>spam</td>\n",
       "      <td>131</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5564</th>\n",
       "      <td>ham</td>\n",
       "      <td>29</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.335215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5565</th>\n",
       "      <td>ham</td>\n",
       "      <td>48</td>\n",
       "      <td>14.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>ham</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>ham</td>\n",
       "      <td>21</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5568 rows × 8110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label  body_len  punct%         0  008704050406  0089mi  0121  \\\n",
       "0      ham       160     2.5  0.0  0.0           0.0     0.0   0.0   \n",
       "1     spam       128     4.7  0.0  0.0           0.0     0.0   0.0   \n",
       "2      ham        49     4.1  0.0  0.0           0.0     0.0   0.0   \n",
       "3      ham        62     3.2  0.0  0.0           0.0     0.0   0.0   \n",
       "4      ham        28     7.1  0.0  0.0           0.0     0.0   0.0   \n",
       "...    ...       ...     ...  ...  ...           ...     ...   ...   \n",
       "5563  spam       131     6.1  0.0  0.0           0.0     0.0   0.0   \n",
       "5564   ham        29     3.4  0.0  0.0           0.0     0.0   0.0   \n",
       "5565   ham        48    14.6  0.0  0.0           0.0     0.0   0.0   \n",
       "5566   ham       100     1.0  0.0  0.0           0.0     0.0   0.0   \n",
       "5567   ham        21     4.8  0.0  0.0           0.0     0.0   0.0   \n",
       "\n",
       "      01223585236  01223585334  ...  zindgi  zoe  zogtoriu  zoom  zouk  zyada  \\\n",
       "0             0.0          0.0  ...     0.0  0.0       0.0   0.0   0.0    0.0   \n",
       "1             0.0          0.0  ...     0.0  0.0       0.0   0.0   0.0    0.0   \n",
       "2             0.0          0.0  ...     0.0  0.0       0.0   0.0   0.0    0.0   \n",
       "3             0.0          0.0  ...     0.0  0.0       0.0   0.0   0.0    0.0   \n",
       "4             0.0          0.0  ...     0.0  0.0       0.0   0.0   0.0    0.0   \n",
       "...           ...          ...  ...     ...  ...       ...   ...   ...    ...   \n",
       "5563          0.0          0.0  ...     0.0  0.0       0.0   0.0   0.0    0.0   \n",
       "5564          0.0          0.0  ...     0.0  0.0       0.0   0.0   0.0    0.0   \n",
       "5565          0.0          0.0  ...     0.0  0.0       0.0   0.0   0.0    0.0   \n",
       "5566          0.0          0.0  ...     0.0  0.0       0.0   0.0   0.0    0.0   \n",
       "5567          0.0          0.0  ...     0.0  0.0       0.0   0.0   0.0    0.0   \n",
       "\n",
       "        é         ü  üll  〨ud  \n",
       "0     0.0  0.000000  0.0  0.0  \n",
       "1     0.0  0.000000  0.0  0.0  \n",
       "2     0.0  0.000000  0.0  0.0  \n",
       "3     0.0  0.000000  0.0  0.0  \n",
       "4     0.0  0.000000  0.0  0.0  \n",
       "...   ...       ...  ...  ...  \n",
       "5563  0.0  0.000000  0.0  0.0  \n",
       "5564  0.0  0.335215  0.0  0.0  \n",
       "5565  0.0  0.000000  0.0  0.0  \n",
       "5566  0.0  0.000000  0.0  0.0  \n",
       "5567  0.0  0.000000  0.0  0.0  \n",
       "\n",
       "[5568 rows x 8110 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalNlp=pd.concat([cleanNlp[['label','body_len','punct%']], X], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kqJIRUufRS93"
   },
   "outputs": [],
   "source": [
    "### Q4. Split the whole data set into training and test datasets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(finalNlp.drop(['label'],axis=1), finalNlp.label, test_size=0.2, random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q5. Create a Ensemble classifier that can predict if the given Text is a Spam or a Ham \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "param = {'n_estimators': [10, 100, 150],\n",
    "        'max_depth': [30, 60, 90, None]}\n",
    "\n",
    "gs = GridSearchCV(rf, param, cv=5, n_jobs=-1)# n_jobs=-1 for parallelizing search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.309112</td>\n",
       "      <td>0.253459</td>\n",
       "      <td>0.284960</td>\n",
       "      <td>0.023554</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 150}</td>\n",
       "      <td>0.967489</td>\n",
       "      <td>0.976457</td>\n",
       "      <td>0.976404</td>\n",
       "      <td>0.973034</td>\n",
       "      <td>0.975281</td>\n",
       "      <td>0.973731</td>\n",
       "      <td>0.003361</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.624628</td>\n",
       "      <td>0.298867</td>\n",
       "      <td>0.242668</td>\n",
       "      <td>0.016967</td>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 100}</td>\n",
       "      <td>0.970852</td>\n",
       "      <td>0.977578</td>\n",
       "      <td>0.976404</td>\n",
       "      <td>0.973034</td>\n",
       "      <td>0.969663</td>\n",
       "      <td>0.973507</td>\n",
       "      <td>0.003067</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.092117</td>\n",
       "      <td>0.329920</td>\n",
       "      <td>0.293479</td>\n",
       "      <td>0.007354</td>\n",
       "      <td>None</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 150}</td>\n",
       "      <td>0.969731</td>\n",
       "      <td>0.978700</td>\n",
       "      <td>0.976404</td>\n",
       "      <td>0.973034</td>\n",
       "      <td>0.969663</td>\n",
       "      <td>0.973507</td>\n",
       "      <td>0.003596</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.471545</td>\n",
       "      <td>0.446929</td>\n",
       "      <td>0.275427</td>\n",
       "      <td>0.005430</td>\n",
       "      <td>90</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 150}</td>\n",
       "      <td>0.966368</td>\n",
       "      <td>0.975336</td>\n",
       "      <td>0.979775</td>\n",
       "      <td>0.974157</td>\n",
       "      <td>0.969663</td>\n",
       "      <td>0.973058</td>\n",
       "      <td>0.004644</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.642742</td>\n",
       "      <td>0.137116</td>\n",
       "      <td>0.256767</td>\n",
       "      <td>0.016861</td>\n",
       "      <td>60</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 100}</td>\n",
       "      <td>0.967489</td>\n",
       "      <td>0.975336</td>\n",
       "      <td>0.975281</td>\n",
       "      <td>0.973034</td>\n",
       "      <td>0.970787</td>\n",
       "      <td>0.972384</td>\n",
       "      <td>0.002969</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "5        9.309112      0.253459         0.284960        0.023554   \n",
       "7        7.624628      0.298867         0.242668        0.016967   \n",
       "11      11.092117      0.329920         0.293479        0.007354   \n",
       "8       10.471545      0.446929         0.275427        0.005430   \n",
       "4        6.642742      0.137116         0.256767        0.016861   \n",
       "\n",
       "   param_max_depth param_n_estimators  \\\n",
       "5               60                150   \n",
       "7               90                100   \n",
       "11            None                150   \n",
       "8               90                150   \n",
       "4               60                100   \n",
       "\n",
       "                                      params  split0_test_score  \\\n",
       "5     {'max_depth': 60, 'n_estimators': 150}           0.967489   \n",
       "7     {'max_depth': 90, 'n_estimators': 100}           0.970852   \n",
       "11  {'max_depth': None, 'n_estimators': 150}           0.969731   \n",
       "8     {'max_depth': 90, 'n_estimators': 150}           0.966368   \n",
       "4     {'max_depth': 60, 'n_estimators': 100}           0.967489   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "5            0.976457           0.976404           0.973034   \n",
       "7            0.977578           0.976404           0.973034   \n",
       "11           0.978700           0.976404           0.973034   \n",
       "8            0.975336           0.979775           0.974157   \n",
       "4            0.975336           0.975281           0.973034   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "5            0.975281         0.973731        0.003361                1  \n",
       "7            0.969663         0.973507        0.003067                2  \n",
       "11           0.969663         0.973507        0.003596                2  \n",
       "8            0.969663         0.973058        0.004644                4  \n",
       "4            0.970787         0.972384        0.002969                5  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_fit = gs.fit(X_train, y_train)\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WXXGNXShRS95"
   },
   "source": [
    "\n",
    "### Vectorize text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iFR4VWHHRS98"
   },
   "source": [
    "### Final evaluation of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v0cxztj2RS99"
   },
   "outputs": [],
   "source": [
    "y_pred = gs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v0cxztj2RS99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.99       955\n",
      "        spam       1.00      0.82      0.90       159\n",
      "\n",
      "    accuracy                           0.97      1114\n",
      "   macro avg       0.99      0.91      0.94      1114\n",
      "weighted avg       0.98      0.97      0.97      1114\n",
      " \n",
      "Accuracy 0.9748653500897666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[955,   0],\n",
       "       [ 28, 131]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Q6. Evaluate the performance of your model using confusion matrix\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(classification_report(y_test,y_pred),\"\\nAccuracy\",accuracy_score(y_test,y_pred))\n",
    "sns.heatmap(confusion_matrix(y_test,y_pred),annot=True)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Random Forest Classifier gives an accuracy of 0.97. High value f1 score is also obtained from the model. 0 hams were predicted as spam and 28 spams were predicted incorrectly as ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Spam-Ham Classifier .ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
